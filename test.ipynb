{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from src.models.unet import UNet\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from src.data.load_data import load_data\n",
    "from src.constants import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "  return 1/(1 + np.exp(-x))\n",
    "\n",
    "def calculate_iou(gt_mask, pred_mask):\n",
    "    overlap = pred_mask * gt_mask\n",
    "    union = (pred_mask + gt_mask) > 0\n",
    "    iou = overlap.sum() / float(union.sum())\n",
    "    return iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/losses/losses_autoaugment.pkl', 'rb') as f:\n",
    "    loss_autoaugment = pickle.load(f)\n",
    "\n",
    "with open('outputs/losses/losses_base.pkl', 'rb') as f:\n",
    "    loss_base = pickle.load(f)\n",
    "\n",
    "with open('outputs/losses/losses_bigaug.pkl', 'rb') as f:\n",
    "    loss_bigaug = pickle.load(f)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(23)\n",
    "\n",
    "axs[0].plot(loss_base['train_loss'], label=\"Train Loss\")\n",
    "axs[0].plot(loss_base['test_loss'], label=\"Test Loss\")\n",
    "axs[0].set_title(\"Train and Test Loss Over Epochs For Base UNet Model\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"BCE Loss\")\n",
    "\n",
    "axs[1].plot(loss_bigaug['train_loss'], label=\"Train Loss\")\n",
    "axs[1].plot(loss_bigaug['test_loss'], label=\"Test Loss\")\n",
    "axs[1].set_title(\"Train and Test Loss Over Epochs For UNet Model With BigAug\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"BCE Loss\")\n",
    "\n",
    "axs[2].plot(loss_autoaugment['train_loss'], label=\"Train Loss\")\n",
    "axs[2].plot(loss_autoaugment['test_loss'], label=\"Test Loss\")\n",
    "axs[2].set_title(\"Train and Test Loss Over Epochs For UNet Model With AutoAugment\")\n",
    "axs[2].set_xlabel(\"Epoch\")\n",
    "axs[2].set_ylabel(\"BCE Loss\")\n",
    "\n",
    "handles, labels = axs[2].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = UNet(3, 1)\n",
    "bigaug_model = UNet(3, 1)\n",
    "autoaugment_model = UNet(3, 1)\n",
    "\n",
    "base_model.load_state_dict(torch.load('outputs/models/unet_base_final.pt', map_location=torch.device('cpu'))) \n",
    "bigaug_model.load_state_dict(torch.load('outputs/models/unet_bigaug_final.pt', map_location=torch.device('cpu'))) \n",
    "autoaugment_model.load_state_dict(torch.load('outputs/models/unet_autoaug_final_new.pt', map_location=torch.device('cpu'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets, train_dataset, test_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = random.sample(range(1, len(test_dataset)), 3)\n",
    "\n",
    "for i in samples:\n",
    "    figure(figsize=(20, 8), dpi=80)\n",
    "\n",
    "    image, mask = test_dataset[i]\n",
    "    mask_binary = mask.numpy() > 0.5\n",
    "    image_dis = image.cpu().permute(1, 2, 0)\n",
    "    image = image.unsqueeze(0).float()\n",
    "\n",
    "    # Original Image \n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image_dis)\n",
    "\n",
    "    # Original Mask\n",
    "    plt.subplot(2, 4, 5)\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.imshow(mask.squeeze(0))\n",
    "\n",
    "    # Base Model\n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.title(\"Base Model Segmentation\")\n",
    "    pred = base_model(image)\n",
    "    pred_np = sig(pred[0][0].detach().numpy())\n",
    "    plt.imshow(pred_np)\n",
    "\n",
    "    # Base Binary\n",
    "    plt.subplot(2, 4, 6)\n",
    "    plt.title(\"Thresholded Base Model Segmentation\")\n",
    "    pred_binary = pred_np > 0.5\n",
    "    plt.imshow(pred_binary)\n",
    "\n",
    "    # BigAug Model\n",
    "    plt.subplot(2, 4, 3)\n",
    "    plt.title(\"BigAug Model Segmentation\")\n",
    "    pred = bigaug_model(image)\n",
    "    pred_np = sig(pred[0][0].detach().numpy())\n",
    "    plt.imshow(pred_np)\n",
    "\n",
    "    # BigAug Binary\n",
    "    plt.subplot(2, 4, 7)\n",
    "    plt.title(\"Thresholded BigAug Model Segmentation\")\n",
    "    pred_binary = pred_np > 0.5\n",
    "    plt.imshow(pred_binary)\n",
    "\n",
    "    # AutoAugment Model\n",
    "    plt.subplot(2, 4, 4)\n",
    "    plt.title(\"AutoAug Model Segmentation\")\n",
    "    pred = autoaugment_model(image)\n",
    "    pred_np = sig(pred[0][0].detach().numpy())\n",
    "    plt.imshow(pred_np)\n",
    "\n",
    "    # AutoAugment Binary\n",
    "    plt.subplot(2, 4, 8)\n",
    "    plt.title(\"Thresholded AutoAugment Model Segmentation\")\n",
    "    pred_binary = pred_np > 0.5\n",
    "    plt.imshow(pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True, num_workers=0)\n",
    "                    for x in ['train', 'test']}\n",
    "\n",
    "test_loader = dset_loaders['test']\n",
    "\n",
    "avg_iou_base_sh = 0\n",
    "avg_iou_big_aug_sh = 0\n",
    "avg_iou_auto_aug_sh = 0\n",
    "\n",
    "avg_iou_base_sk = 0\n",
    "avg_iou_big_aug_sk = 0\n",
    "avg_iou_auto_aug_sk = 0\n",
    "\n",
    "count_sh = 0\n",
    "count_sk = 0\n",
    "\n",
    "loop = tqdm(test_loader)\n",
    "\n",
    "for (i, (image, mask)) in enumerate(loop):\n",
    "    with torch.no_grad():\n",
    "        mask_binary = mask.numpy() > 0.5\n",
    "        \n",
    "        pred_base = base_model(image)\n",
    "        pred_base_np = sig(pred_base[0][0].numpy())\n",
    "        pred_base_binary = pred_base_np > 0.5\n",
    "\n",
    "        pred_big_aug = bigaug_model(image)\n",
    "        pred_big_aug_np = sig(pred_big_aug[0][0].numpy())\n",
    "        pred_big_aug_binary = pred_big_aug_np > 0.5\n",
    "\n",
    "        pred_auto_aug = autoaugment_model(image)\n",
    "        pred_auto_aug_np = sig(pred_auto_aug[0][0].numpy())\n",
    "        pred_auto_aug_binary = pred_auto_aug_np > 0.5\n",
    "        \n",
    "        if i < 176: \n",
    "            avg_iou_base_sk += calculate_iou(mask_binary, pred_base_binary)\n",
    "            avg_iou_big_aug_sk += calculate_iou(mask_binary, pred_big_aug_binary)\n",
    "            avg_iou_auto_aug_sk += calculate_iou(mask_binary, pred_auto_aug_binary)\n",
    "            count_sk += 1\n",
    "        else: \n",
    "            avg_iou_base_sh += calculate_iou(mask_binary, pred_base_binary)\n",
    "            avg_iou_big_aug_sh += calculate_iou(mask_binary, pred_big_aug_binary)\n",
    "            avg_iou_auto_aug_sh += calculate_iou(mask_binary, pred_auto_aug_binary)\n",
    "            count_sh += 1\n",
    "\n",
    "avg_iou_base_sk = avg_iou_base_sk / count_sk\n",
    "avg_iou_big_aug_sk = avg_iou_big_aug_sk / count_sk\n",
    "avg_iou_auto_aug_sk = avg_iou_auto_aug_sk / count_sk\n",
    "\n",
    "avg_iou_base_sh = avg_iou_base_sh / count_sh\n",
    "avg_iou_big_aug_sh = avg_iou_big_aug_sh / count_sh\n",
    "avg_iou_auto_aug_sh = avg_iou_auto_aug_sh / count_sh\n",
    "\n",
    "print(avg_iou_base_sk, avg_iou_big_aug_sk, avg_iou_auto_aug_sk, avg_iou_base_sh, avg_iou_big_aug_sh, avg_iou_auto_aug_sh)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
